{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_data():\n",
    "    # get all available time stamps\n",
    "    stampsurl = \"https://www.smard.de/app/chart_data/410/DE/index_hour.json\"\n",
    "    response = requests.get(stampsurl)\n",
    "    # ignore first 6 years (don't need those in the baseline and speeds the code up a bit)\n",
    "    timestamps = list(response.json()[\"timestamps\"])[6 * 52 :]\n",
    "\n",
    "    col_names = [\"date_time\", \"Netzlast_Gesamt\"]\n",
    "    energydata = pd.DataFrame(columns=col_names)\n",
    "\n",
    "    # loop over all available timestamps\n",
    "    for stamp in tqdm(timestamps):\n",
    "        dataurl = (\n",
    "            \"https://www.smard.de/app/chart_data/410/DE/410_DE_hour_\"\n",
    "            + str(stamp)\n",
    "            + \".json\"\n",
    "        )\n",
    "        response = requests.get(dataurl)\n",
    "        rawdata = response.json()[\"series\"]\n",
    "        for i in range(len(rawdata)):\n",
    "            rawdata[i][0] = datetime.fromtimestamp(\n",
    "                int(str(rawdata[i][0])[:10])\n",
    "            ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        energydata = pd.concat([energydata, pd.DataFrame(rawdata, columns=col_names)])\n",
    "\n",
    "    energydata = energydata.dropna()\n",
    "    energydata[\"date_time\"] = pd.to_datetime(energydata.date_time) + pd.DateOffset(\n",
    "        hours=1\n",
    "    )  # adjust for correct time 'label'\n",
    "    # set date_time as index\n",
    "    energydata.set_index(\"date_time\", inplace=True)\n",
    "\n",
    "    return energydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_energy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Rename column for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Netzlast_Gesamt\": \"gesamt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Rescale Netzlast so it fits requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gesamt\"] = df[\"gesamt\"] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Check dtypes and if columns contain and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Define weekday column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df.index.weekday  # Monday=0, Sunday=6\n",
    "# df[\"time\"] = df.index.strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Lead times are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons_def = [36, 40, 44, 60, 64, 68]  # [24 + 12*i for i in range(5)]\n",
    "horizons_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Adapt horzions so they actually fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [h + 0 for h in horizons_def]\n",
    "horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_horizon(last_ts, horizon):\n",
    "    return last_ts + pd.DateOffset(hours=horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_IDX = -1\n",
    "LAST_DATE = df.iloc[LAST_IDX].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Get time and date that correspond to the lead times (starting at the last observation in our data which should be the respective thursday 0:00)  \n",
    "*Attention*: if the last timestamp in the data is not thursday 0:00, you have to adjust your lead times accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_date = [get_date_from_horizon(LAST_DATE, h) for h in horizons]\n",
    "horizon_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "quantile levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = [0.025, 0.25, 0.5, 0.75, 0.975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows correspond to horizon, columns to quantile level\n",
    "pred_baseline = np.zeros((6, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_t = 100\n",
    "\n",
    "for i, d in enumerate(horizon_date):\n",
    "    weekday = d.weekday()\n",
    "    hour = d.hour\n",
    "\n",
    "    df_tmp = df.iloc[:LAST_IDX]\n",
    "\n",
    "    cond = (df_tmp.weekday == weekday) & (df_tmp.index.time == d.time())\n",
    "\n",
    "    pred_baseline[i, :] = np.quantile(df_tmp[cond].iloc[-last_t:][\"gesamt\"], q=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Visually check if quantiles make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = horizons\n",
    "_ = plt.plot(x, pred_baseline, ls=\"\", marker=\"o\", c=\"black\")\n",
    "_ = plt.xticks(x, x)\n",
    "_ = plt.plot((x, x), (pred_baseline[:, 0], pred_baseline[:, -1]), c=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "date_str = datetime.today().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = date.today()  # - timedelta(days=1)\n",
    "date_str = date_str.strftime(\"%Y%m%d\")\n",
    "date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(\n",
    "    {\n",
    "        \"forecast_date\": date_str,\n",
    "        \"target\": \"energy\",\n",
    "        \"horizon\": [str(h) + \" hour\" for h in horizons_def],\n",
    "        \"q0.025\": pred_baseline[:, 0],\n",
    "        \"q0.25\": pred_baseline[:, 1],\n",
    "        \"q0.5\": pred_baseline[:, 2],\n",
    "        \"q0.75\": pred_baseline[:, 3],\n",
    "        \"q0.975\": pred_baseline[:, 4],\n",
    "    }\n",
    ")\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change this\n",
    "PATH = \"/save/to/path\"\n",
    "\n",
    "\n",
    "df_sub.to_csv(PATH + date_str + \"_power_benchmark.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
